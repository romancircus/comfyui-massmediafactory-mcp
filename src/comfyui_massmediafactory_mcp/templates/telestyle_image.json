{
  "_meta": {
    "description": "TeleStyle Image - Apply style from reference to keyframe for I2V workflows",
    "model": "qwen_image_edit_2511",
    "type": "style_transfer",
    "parameters": [
      "CONTENT_IMAGE",
      "STYLE_IMAGE",
      "SEED",
      "CFG",
      "STEPS"
    ],
    "defaults": {
      "SEED": 42,
      "CFG": 2.0,
      "STEPS": 20
    },
    "agent_notes": {
      "usage": "For styling keyframes BEFORE I2V animation (Wan 2.6). Pass keyframe as CONTENT_IMAGE, character style key as STYLE_IMAGE.",
      "prompt": "Fixed TeleStyle prompt - transfers style of Figure 2 (style) to Figure 1 (content) while preserving content characteristics.",
      "cfg": "Keep 2.0-2.5. Higher causes color distortion.",
      "pipeline": "Keyframe -> TeleStyle Image -> Styled Keyframe -> Wan 2.6 I2V",
      "vram": "~16GB with FP8 quantization",
      "size": "Auto-detected from content image via GetImageSize node."
    },
    "vram_min": 16,
    "tags": [
      "capability:style_transfer"
    ]
  },
  "1": {
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Content (Keyframe)"
    },
    "inputs": {
      "image": "{{CONTENT_IMAGE}}"
    }
  },
  "2": {
    "class_type": "LoadImage",
    "_meta": {
      "title": "Load Style Reference"
    },
    "inputs": {
      "image": "{{STYLE_IMAGE}}"
    }
  },
  "3": {
    "class_type": "UNETLoader",
    "_meta": {
      "title": "Load Qwen Edit Model"
    },
    "inputs": {
      "unet_name": "qwen_image_edit_2511_fp8mixed.safetensors",
      "weight_dtype": "default"
    }
  },
  "4": {
    "class_type": "CLIPLoader",
    "_meta": {
      "title": "Load CLIP"
    },
    "inputs": {
      "clip_name": "qwen_2.5_vl_7b_fp8_scaled.safetensors",
      "type": "qwen_image"
    }
  },
  "5": {
    "class_type": "VAELoader",
    "_meta": {
      "title": "Load VAE"
    },
    "inputs": {
      "vae_name": "qwen_image_vae.safetensors"
    }
  },
  "6": {
    "class_type": "TextEncodeQwenImageEditPlus",
    "_meta": {
      "title": "Encode TeleStyle Prompt"
    },
    "inputs": {
      "clip": [
        "4",
        0
      ],
      "prompt": "Style Transfer the style of Figure 2 to Figure 1, and keep the content and characteristics of Figure 1.",
      "vae": [
        "5",
        0
      ],
      "image1": [
        "1",
        0
      ],
      "image2": [
        "2",
        0
      ]
    }
  },
  "7": {
    "class_type": "ConditioningZeroOut",
    "_meta": {
      "title": "Negative Conditioning"
    },
    "inputs": {
      "conditioning": [
        "6",
        0
      ]
    }
  },
  "8": {
    "class_type": "GetImageSize",
    "_meta": {
      "title": "Get Content Size"
    },
    "inputs": {
      "image": [
        "1",
        0
      ]
    }
  },
  "9": {
    "class_type": "EmptyQwenImageLayeredLatentImage",
    "_meta": {
      "title": "Create Latent"
    },
    "inputs": {
      "width": [
        "8",
        0
      ],
      "height": [
        "8",
        1
      ],
      "layers": 0,
      "batch_size": 1
    }
  },
  "10": {
    "class_type": "KSampler",
    "_meta": {
      "title": "Sample"
    },
    "inputs": {
      "model": [
        "3",
        0
      ],
      "seed": "{{SEED}}",
      "steps": "{{STEPS}}",
      "cfg": "{{CFG}}",
      "sampler_name": "euler",
      "scheduler": "normal",
      "positive": [
        "6",
        0
      ],
      "negative": [
        "7",
        0
      ],
      "latent_image": [
        "9",
        0
      ],
      "denoise": 1.0
    }
  },
  "11": {
    "class_type": "VAEDecode",
    "_meta": {
      "title": "Decode"
    },
    "inputs": {
      "samples": [
        "10",
        0
      ],
      "vae": [
        "5",
        0
      ]
    }
  },
  "12": {
    "class_type": "SaveImage",
    "_meta": {
      "title": "Save Output"
    },
    "inputs": {
      "images": [
        "11",
        0
      ],
      "filename_prefix": "telestyle_image"
    }
  }
}