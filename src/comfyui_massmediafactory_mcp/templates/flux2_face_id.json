{
  "_meta": {
    "description": "FLUX.2 Face ID - Force specific face identity in generated images",
    "model": "FLUX.2-dev",
    "type": "txt2img_faceid",
    "use_case": "Generate images with consistent face identity (replaces Midjourney --cref)",
    "replaces": "Midjourney --cref (character reference)",
    "parameters": [
      "PROMPT",
      "FACE_IMAGE",
      "FACE_STRENGTH",
      "SEED",
      "WIDTH",
      "HEIGHT",
      "STEPS",
      "GUIDANCE"
    ],
    "defaults": {
      "WIDTH": 1024,
      "HEIGHT": 1024,
      "SEED": 42,
      "STEPS": 20,
      "GUIDANCE": 3.5,
      "FACE_STRENGTH": 0.85
    },
    "agent_notes": {
      "FACE_IMAGE": "Path to reference face image (clear frontal face works best)",
      "FACE_STRENGTH": "0.7-0.9 for strong likeness, 0.5-0.7 for subtle influence",
      "tips": [
        "Use clear, well-lit frontal face photos",
        "Multiple reference images improve consistency",
        "Lower strength allows more style variation",
        "Works best with realistic prompts"
      ]
    },
    "custom_nodes_required": [
      "ComfyUI_IPAdapter_plus",
      "ComfyUI_InstantID"
    ],
    "models_required": [
      "ip-adapter.bin",
      "antelopev2"
    ],
    "vram_required_gb": 18,
    "compatibility_note": "This template uses IP-Adapter for face consistency. For FLUX, ensure you have FLUX-compatible IP-Adapter models installed. Alternative: Use PuLID or InstantID custom nodes.",
    "vram_min": 16,
    "tags": [
      "model:flux",
      "capability:face_id"
    ],
    "version": "1.0.0",
    "hub_hash": "9b6e60d09b89a646"
  },
  "1": {
    "class_type": "UNETLoader",
    "inputs": {
      "unet_name": "flux1-dev-fp8.safetensors",
      "weight_dtype": "fp8_e4m3fn"
    }
  },
  "2": {
    "class_type": "DualCLIPLoader",
    "inputs": {
      "clip_name1": "clip_l.safetensors",
      "clip_name2": "t5xxl_fp16.safetensors",
      "type": "flux"
    }
  },
  "3": {
    "class_type": "VAELoader",
    "inputs": {
      "vae_name": "ae.safetensors"
    }
  },
  "4": {
    "class_type": "LoadImage",
    "_comment": "Load reference face image",
    "inputs": {
      "image": "{{FACE_IMAGE}}"
    }
  },
  "5": {
    "class_type": "IPAdapterModelLoader",
    "_comment": "Load IP-Adapter model (use FLUX-compatible version)",
    "inputs": {
      "ipadapter_file": "ip-adapter_sd15.safetensors"
    }
  },
  "6": {
    "class_type": "CLIPVisionLoader",
    "_comment": "Load CLIP Vision for image encoding",
    "inputs": {
      "clip_name": "clip-vit-h-14-laion2B-s32B-b79K.safetensors"
    }
  },
  "7": {
    "class_type": "IPAdapterApply",
    "_comment": "Apply face reference to model conditioning",
    "inputs": {
      "model": [
        "1",
        0
      ],
      "ipadapter": [
        "5",
        0
      ],
      "clip_vision": [
        "6",
        0
      ],
      "image": [
        "4",
        0
      ],
      "weight": "{{FACE_STRENGTH}}",
      "weight_type": "linear",
      "start_at": 0.0,
      "end_at": 1.0
    }
  },
  "8": {
    "class_type": "CLIPTextEncode",
    "inputs": {
      "clip": [
        "2",
        0
      ],
      "text": "{{PROMPT}}"
    }
  },
  "9": {
    "class_type": "FluxGuidance",
    "inputs": {
      "conditioning": [
        "8",
        0
      ],
      "guidance": "{{GUIDANCE}}"
    }
  },
  "10": {
    "class_type": "EmptySD3LatentImage",
    "inputs": {
      "width": "{{WIDTH}}",
      "height": "{{HEIGHT}}",
      "batch_size": 1
    }
  },
  "11": {
    "class_type": "KSamplerSelect",
    "inputs": {
      "sampler_name": "euler"
    }
  },
  "12": {
    "class_type": "BasicScheduler",
    "inputs": {
      "model": [
        "7",
        0
      ],
      "scheduler": "simple",
      "steps": "{{STEPS}}",
      "denoise": 1.0
    }
  },
  "13": {
    "class_type": "RandomNoise",
    "inputs": {
      "noise_seed": "{{SEED}}"
    }
  },
  "14": {
    "class_type": "BasicGuider",
    "inputs": {
      "model": [
        "7",
        0
      ],
      "conditioning": [
        "9",
        0
      ]
    }
  },
  "15": {
    "class_type": "SamplerCustomAdvanced",
    "inputs": {
      "noise": [
        "13",
        0
      ],
      "guider": [
        "14",
        0
      ],
      "sampler": [
        "11",
        0
      ],
      "sigmas": [
        "12",
        0
      ],
      "latent_image": [
        "10",
        0
      ]
    }
  },
  "16": {
    "class_type": "VAEDecode",
    "inputs": {
      "samples": [
        "15",
        0
      ],
      "vae": [
        "3",
        0
      ]
    }
  },
  "17": {
    "class_type": "SaveImage",
    "inputs": {
      "images": [
        "16",
        0
      ],
      "filename_prefix": "faceid_output"
    }
  }
}
